{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"headline\">\n",
    "Language Technology / Sprachtechnologie\n",
    "<br><br>\n",
    "Wintersemester 2019/2020\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"description\">\n",
    "    Übung zum Thema <i id=\"topic\">\"Grammatical Error Correction/Spelling Correction\"</i>\n",
    "    <br><br>\n",
    "    Deadline Abgabe: <i #id=\"submission\">Thursday, 16.01.2020 (23:55 Uhr)</i>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>/* Style des gesamten Dokuments */\n",
       "#notebook-container {\n",
       "\tfont-family: \"NimbusMonL-ReguObli\";\n",
       "\tfont-size: 120%\n",
       "}\n",
       "\n",
       "/* Style für die Überschrift: Zentriert diese und stellt sie fett dar. */\n",
       ".headline {\n",
       "\ttext-align: center;\n",
       "\tfont-weight: bold;\n",
       "\tfont-size: 185.7%\n",
       "}\n",
       "\n",
       "/* Style für die Aufgabenbeschreibung. Z.B.: \"Übung zum Thema...\" */\n",
       ".description {\n",
       "\ttext-align: center;\n",
       "\tfont-size: 145.7%\n",
       "}\n",
       "\n",
       "/* Hebt das Abgabedatum fett und kursiv hervor */\n",
       "#submission {\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "\n",
       "/* Style für das eigentliche Thema. Z.B.: \"Intelligenz\" */\n",
       "#topic {\n",
       "\tfont-style: italic;\n",
       "}\n",
       "\n",
       ".task_description {\n",
       "\tmargin-bottom: 20px;\n",
       "}\n",
       "\n",
       "/* Hebt die Aufgabennummerierung fett hervor. */\n",
       ".task {\n",
       "\tfont-style: normal;\n",
       "\tfont-weight: bold;\n",
       "\tfont-size: 120%;\n",
       "\tborder-bottom: 2px solid black;\n",
       "  background-color: #97CAEF;\n",
       "  color: black;\n",
       "\tpadding: 2px;\n",
       "  padding-left: 50px;\n",
       "  padding-right: 50px;\n",
       "}\n",
       "\n",
       ".subtask {\n",
       "\tfont-style: normal;\n",
       "\tfont-size: 100%;\n",
       "  background-color: #CAFAFE;\n",
       "  color: black;\n",
       "\tpadding: 2px;\n",
       "  padding-left: 25px;\n",
       "  padding-right: 25px;\n",
       "}\n",
       "\n",
       ".l1 {\n",
       "\tfont-style: normal;\n",
       "\tfont-size: 100%;\n",
       "  background-color: #14A76C;\n",
       "  color: black;\n",
       "\tpadding: 2px;\n",
       "  padding-left: 5px;\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".l2 {\n",
       "\tfont-style: normal;\n",
       "\tfont-size: 100%;\n",
       "  background-color: #FFE400;\n",
       "  color: black;\n",
       "\tpadding: 2px;\n",
       "  padding-left: 5px;\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".l3 {\n",
       "\tfont-style: normal;\n",
       "\tfont-size: 100%;\n",
       "  background-color: #FF652F;\n",
       "  color: black;\n",
       "\tpadding: 2px;\n",
       "  padding-left: 5px;\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".points {\n",
       "\tfont-style: italic;\n",
       "}\n",
       "\n",
       "ol.lower_roman {\n",
       "    list-style-type: lower-roman;\n",
       "}\n",
       "\n",
       "ol.characters {\n",
       "    list-style-type: lower-alpha;\n",
       "}\n",
       "\n",
       "/* Style einer Code-Cell */\n",
       ".CodeMirror-code {\n",
       "\tbackground-color: #ededed\n",
       "}\n",
       "\n",
       "/* Style eines Kommentars im Code ändern. */\n",
       ".cm-s-ipython span.cm-comment {\n",
       "\n",
       "}\n",
       "\n",
       ".cm-s-ipython span.cm-atom {\n",
       "\n",
       "}\n",
       "\n",
       ".cm-s-ipython span.cm-number {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style eines Python-Keywords ändern */\n",
       ".cm-s-ipython span.cm-keyword {\n",
       "\tcolor: #B000B0\n",
       "}\n",
       "\n",
       ".cm-s-ipython span.cm-def {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style einer Python-Variable ändern */\n",
       ".cm-s-ipython span.cm-variable {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style einer Property ändern */\n",
       ".cm-s-ipython span.cm-property {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style eines Python-Operators ändern */\n",
       ".cm-s-ipython span.cm-operator {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style eines Python-Strings ändern */\n",
       ".cm-s-ipython span.cm-string {\n",
       "\tcolor: brown;\n",
       "}\n",
       "\n",
       "/* Style einer eingebauten Funktion ändern (z.B. \"open\") */\n",
       ".cm-s-ipython span.cm-builtin {\n",
       "\n",
       "}\n",
       "\n",
       "/* Hebt hervor, welche Klammern zueinander passen */\n",
       ".cm-s-ipython .CodeMirror-matchingbracket {\n",
       "\n",
       "}\n",
       "\n",
       ".cm-s-ipython span.cm-variable-2 {\n",
       "\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>\" + open(\"style.css\").read() + \"</style>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk import bigrams\n",
    "from nltk import FreqDist\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 10.1:</i> <br>\n",
    "</div>\n",
    "\n",
    "Which statements are true?\n",
    "\n",
    "1. Essay Scoring, Machine Translation and Grammatical Error correction can technically be treated as the same task.\n",
    "\n",
    "2. The Levenshtein distance between two strings is the minimum number of edit operations (substitution, insertion, deletion) that is necessary to transform one string into the other.\n",
    "\n",
    "3. Spelling correction: Longer words are easier to correct than shorter words.\n",
    "\n",
    "4. The Levenshtein distance is based on the assumption that there is exactly one optimal alignment between two strings.\n",
    "\n",
    "5. The Levenshtein distance can only be computed if the strings have the same length. If the strings have different lengths, we need to compute the Damerau-Levenshtein distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n",
    "1. False. Machine Translation and Grammatical Error Correction can indeed be seen as variants of the same task, namely a sequence-to-sequence problem in which we want to transform an input sequence (of variable length) to an output sequence (which not necessarily has the same length). Essay Scoring, in contrast, is a classification task in which an input sequence is assigned a score.\n",
    "\n",
    "2. True.\n",
    "\n",
    "3. Often true (but not always). Shorter words tend to have more \"neighbors\", i.e. words that differ by only one letter (Levenshtein distance = 1), for example \"poice\" could be corrected to \"police\", \"price\", \"voice\", \"poise\"... with one edit, while long words often just have a unique correction candidate  (e.g. \"abministration\" : \"administration\"). The statement is not generally true, of course: How hard it is to correct a misspelling is  dependent on many other factors, e.g. the type of error, the correction model (different weights for different edits) etc.\n",
    "\n",
    "4. False. There can be several alignments between two strings which require the same (minimum) number of edits.\n",
    "\n",
    "5. False. Levenshtein distance can be computed between strings of any length. The Damerau-Levenshtein distance is a variant of the Levenshtein distance in which also the transposition of two characters counts as one edit operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit Distance Manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 10.2:</i><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">10.2.1</i> <i class=\"l1\">L1</i> <br>\n",
    "</div>\n",
    "\n",
    "Given the following alignment between the words \"rot\" and \"Wort\", how many and which edit operations are needed to convert one string into the other? (Do not count copying an identical character as an edit operation here)\n",
    "\n",
    "| _ | r | o | t |\n",
    "|---|---|---|---|\n",
    "| W | o | r | t |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n",
    "3 edit operations: insert \"W\", replace \"r\" with \"o\", replace \"o\" with \"r\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">10.2.2</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Is this already the optimal alignment? Compute manually the minimum edit distance (Levenshtein distance) between the source word \"rot\" and the target word \"Wort\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n",
    "|   |   | W | o | r | t |\n",
    "|---|---|---|---|---|---|\n",
    "|   | 0 | 1 | 2 | 3 | 4 |\n",
    "| r | 1 | 1 | 2 | 2 | 3 |\n",
    "| o | 2 | 2 | 1 | 2 | 3 |\n",
    "| t | 3 | 3 | 2 | 2 | 2 |\n",
    "\n",
    "The minimum edit distance is 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">10.2.3</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Find the best alignment(s) between \"rot\" and \"Wort\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "    \n",
    "| r | o | _ | t |\n",
    "|---|---|---|---|\n",
    "| W | o | r | t |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit Distance Automatically\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 10.3:</i><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">10.3.1</i> <i class=\"l1\">L1</i> <br>\n",
    "</div>\n",
    "\n",
    "What does the following code do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein(seq1, seq2):\n",
    "    \n",
    "    size_x = len(seq1) + 1\n",
    "    size_y = len(seq2) + 1\n",
    "    \n",
    "    matrix = np.zeros ((size_x, size_y))\n",
    "    \n",
    "    for x in range(size_x):\n",
    "        matrix [x, 0] = x\n",
    "    for y in range(size_y):\n",
    "        matrix [0, y] = y\n",
    "\n",
    "    for x in range(1, size_x):\n",
    "        for y in range(1, size_y):\n",
    "            \n",
    "            if seq1[x-1] == seq2[y-1]:\n",
    "                cost = 0\n",
    "            else:\n",
    "                cost = 1\n",
    "                \n",
    "            matrix [x,y] = min(\n",
    "                matrix[x-1,y] + 1,\n",
    "                matrix[x-1,y-1] + cost,\n",
    "                matrix[x,y-1] + 1\n",
    "                )\n",
    "            \n",
    "    print (matrix)\n",
    "    return (matrix[size_x - 1, size_y - 1])\n",
    "\n",
    "print(levenshtein(\"rot\", \"Wort\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "    \n",
    "This is an implementation of Levenshtein distance (dynamic programming), which outputs the computed matrix and the final minimum edit distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">10.3.2</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Change the function above in a way so that wrong lettercase (e.g. changing \"r\" to \"R\" only has a cost of 0.5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein(seq1, seq2):\n",
    "    \n",
    "    size_x = len(seq1) + 1\n",
    "    size_y = len(seq2) + 1\n",
    "    \n",
    "    matrix = np.zeros ((size_x, size_y))\n",
    "    \n",
    "    for x in range(size_x):\n",
    "        matrix [x, 0] = x\n",
    "    for y in range(size_y):\n",
    "        matrix [0, y] = y\n",
    "    \n",
    "        \n",
    "    for x in range(1, size_x):\n",
    "        for y in range(1, size_y):\n",
    "            \n",
    "            if seq1[x-1] == seq2[y-1]:\n",
    "                cost = 0\n",
    "            \n",
    "            ### cost for only changing letter case is set to 0.5\n",
    "            elif seq1[x-1].lower() == seq2[y-1].lower():\n",
    "                cost = 0.5\n",
    "            \n",
    "            else:\n",
    "                cost = 1\n",
    "                \n",
    "            matrix [x,y] = min(\n",
    "                matrix[x-1,y] + 1,\n",
    "                matrix[x-1,y-1] + cost,\n",
    "                matrix[x,y-1] + 1\n",
    "                )\n",
    "            \n",
    "    #print (matrix)\n",
    "    return (matrix[size_x - 1, size_y - 1])\n",
    "\n",
    "print(levenshtein(\"Rot\", \"rot\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">10.3.3</i> <i class=\"l1\">L1</i> <br>\n",
    "</div>\n",
    "\n",
    "Think of other adjustments to the code that could be useful for using Levenshtein distance in a spellchecking algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n",
    "Some ideas are:\n",
    "\n",
    "- Multi-letter graphemes like \"sch\", \"ch\", \"qu\" in German should be treated like fixed units rather than single letters\n",
    "\n",
    "- Depending on the application/target group it would for example be useful to reduce the costs for \n",
    " \n",
    " - substituting a letter with another letter that is adjacent to it on a standard keyboard (e.g. \"a\" and \"s\")\n",
    " - substituting two letters with a similar pronunciation (e.g. \"f\" and \"v\")\n",
    " - insertion if the missing character is part of a double consonant (e.g. \"komen\" for \"kommen\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-Word Spelling Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 10.4:</i><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">10.4.1</i> <i class=\"l1\">L1</i> <br>\n",
    "</div>\n",
    "\n",
    "What does the following code do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"deu_news_2015_30K-sentences.txt\", mode=\"r\", encoding=\"utf-8\") as f:\n",
    "    corpus = f.read().splitlines()\n",
    "\n",
    "sentences = [word_tokenize(sentence) for sentence in corpus]\n",
    "sentences = [sentence[1:] for sentence in sentences]\n",
    "\n",
    "bi = [bigrams(sentence) for sentence in sentences]\n",
    "bi = [bigram for sublist in bi for bigram in sublist]\n",
    "\n",
    "fdist = FreqDist(bi)\n",
    "print(fdist.most_common(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n",
    "A file is read in which contains one sentence per line. The file is tokenized and the first token is deleted (contains the line number). Each sentence is split into bigrams (so that there are no bigrams across sentence boundaries because the sentences do not form a coherent text). All bigrams are then stored in one list, over which a frequency distribution is calculated. The five most frequent bigrams are then printed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">10.4.2</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Take the sentence \"Das ist seid Jahren ein Problem\". Which bigram(s) is/are the most infrequent ones given the news corpus provided above? What could it indicate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"Das ist seid Jahren ein Problem.\"\n",
    "sent = word_tokenize(sent)\n",
    "sent_bi = bigrams(sent)\n",
    "\n",
    "for bi in sent_bi:\n",
    "    print(bi, fdist[bi])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The low frequency of the bigrams including \"seid\" suggest that this could be a real-word spelling error. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">10.4.3</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "How many different unigram **types** are there in the news corpus? Which are the five most frequent ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams = [word for sublist in sentences for word in sublist]\n",
    "uni_types = set(unigrams)\n",
    "print(len(uni_types))\n",
    "uni_fdist = FreqDist(unigrams)\n",
    "print(uni_fdist.most_common(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">10.4.4</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Which words from the news corpus have a Levenshtein distance of 1 to \"seid\"? These will be the correction candidates for our real-word error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = []\n",
    "for word in uni_types:\n",
    "    if levenshtein(word, \"seid\") == 1:\n",
    "        candidates.append(word)\n",
    "print(candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">10.4.5</i> <i class=\"l3\">L3</i> <br>\n",
    "</div>\n",
    "\n",
    "Which of the candidate words is most likely to appear in the bigrams (\"ist\", x) and (x, \"Jahren\")?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ist_x = {word: fdist[\"ist\", word] for word in candidates}\n",
    "print(max(ist_x))\n",
    "\n",
    "x_Jahren = {word: fdist[word, \"Jahren\"] for word in candidates}\n",
    "print(max(x_Jahren))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">10.1.</i> :::10 Homework points:::\n",
    "</div>\n",
    "\n",
    "\n",
    "The text *spelling_homework.csv* was written by a primary school child. It contains 75 tokens, of which 30 are spelled incorrectly. There is one token per line. The first column contains the original spelling and the second column the gold solution, i.e. the correct spelling of every word. The text is about two kids, Lea and Lars, and their dog Dodo. \n",
    "\n",
    "Implement a spelling corrector that predicts the correct spelling for each word. This means, it has to decide for every word whether it needs correcting and if this is the case, it has to provide one correction (not multiple correction candidates -- you have to decide for one). A correction counts as correct if it exactly matches the gold correction of the word (including letter case). You get the full homework points if your spellchecker reduces the number of incorrectly spelled words from 30 to 27 or less (keep in mind that your spelling corrector does not know beforehand which of the words are spelled incorrectly, so it may happen that you change a correct word to something incorrect, which then counts as a misspelling as well). \n",
    "\n",
    "You have to use the provided template for your solution. The function ``correctText()`` takes as input a list of tokens and outputs a list of corrected tokens (the lists have to have the same length). The other functions should not be changed. They can be used to evaluate your corrections.  \n",
    "\n",
    "Note: It is not a valid solution to simply map every word to its correction ;-) Your solution should be general enough to work for other texts as well (see Challenge below).\n",
    "\n",
    "\n",
    "### Challenge\n",
    "\n",
    "::: 1 extra exam bonus point :::\n",
    "\n",
    "Your homework submission will automatically enter a challenge. Your spelling corrector will be tested on another text with similar spelling errors and 1 extra exam bonus point will be awarded to the 3 teams who achieve the highest number of correct words in the test text. The final results will be presented in the lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Template:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctText(listOfTokens):\n",
    "    \n",
    "    #the spell checking functionality goes here\n",
    "    #right now the function just outputs every word as it is\n",
    "    corrections = [word for word in listOfTokens]\n",
    "    \n",
    "    return corrections\n",
    "    \n",
    "    \n",
    "def evaluate(corrected_tokens, original_spellings, solution):\n",
    "    \n",
    "    #make sure that all three lists have the same length\n",
    "    assert len(corrected_tokens) == len(original_spellings) == len(solution), \"Error. The lists with proposed corrections, original tokens and the solution do not have the same lengths.\"\n",
    "    \n",
    "    #count nuber of incorrect tokens (=whenever there is a difference between the proposed correction and the gold solution)\n",
    "    incorrect_tokens = sum(1 for i in range(len(corrected_tokens)) if corrected_tokens[i] != solution[i])\n",
    "    \n",
    "    print(\"Number of incorrect tokens in the text:\", incorrect_tokens)\n",
    "    \n",
    "\n",
    "def correct_and_evaluate(filename):\n",
    "    \n",
    "    #read in text\n",
    "    with open(filename, mode=\"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read().splitlines()\n",
    "    text = [line.split(\"\\t\") for line in text]\n",
    "    \n",
    "    #comment in to see the text\n",
    "    #for line in text:\n",
    "    #    print(line[0], line[1])\n",
    "\n",
    "    #extract original spelling and solution for every word\n",
    "    original_spellings = [line[0] for line in text]\n",
    "    solution = [line[1] for line in text]\n",
    "    \n",
    "    #correct tokens\n",
    "    proposed_corrections = correctText(original_spellings)\n",
    "    \n",
    "    #evaluate corrections\n",
    "    evaluate(proposed_corrections, original_spellings, solution)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_and_evaluate(\"spelling_homework.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
