{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>/* Style des gesamten Dokuments */\n",
       "#notebook-container {\n",
       "\tfont-family: \"NimbusMonL-ReguObli\";\n",
       "\tfont-size: 120%\n",
       "}\n",
       "\n",
       "/* Style f√ºr die √úberschrift: Zentriert diese und stellt sie fett dar. */\n",
       ".headline {\n",
       "\ttext-align: center;\n",
       "\tfont-weight: bold;\n",
       "\tfont-size: 185.7%\n",
       "}\n",
       "\n",
       "/* Style f√ºr die Aufgabenbeschreibung. Z.B.: \"√úbung zum Thema...\" */\n",
       ".description {\n",
       "\ttext-align: center;\n",
       "\tfont-size: 145.7%\n",
       "}\n",
       "\n",
       "/* Hebt das Abgabedatum fett und kursiv hervor */\n",
       "#submission {\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "\n",
       "/* Style f√ºr das eigentliche Thema. Z.B.: \"Intelligenz\" */\n",
       "#topic {\n",
       "\tfont-style: italic;\n",
       "}\n",
       "\n",
       ".task_description {\n",
       "\tmargin-bottom: 20px;\n",
       "}\n",
       "\n",
       "/* Hebt die Aufgabennummerierung fett hervor. */\n",
       ".task {\n",
       "\tfont-style: normal;\n",
       "\tfont-weight: bold;\n",
       "\tfont-size: 120%;\n",
       "\tborder-bottom: 2px solid black;\n",
       "  background-color: #97CAEF;\n",
       "  color: black;\n",
       "\tpadding: 2px;\n",
       "  padding-left: 50px;\n",
       "  padding-right: 50px;\n",
       "}\n",
       "\n",
       ".subtask {\n",
       "\tfont-style: normal;\n",
       "\tfont-size: 100%;\n",
       "  background-color: #CAFAFE;\n",
       "  color: black;\n",
       "\tpadding: 2px;\n",
       "  padding-left: 25px;\n",
       "  padding-right: 25px;\n",
       "}\n",
       "\n",
       ".l1 {\n",
       "\tfont-style: normal;\n",
       "\tfont-size: 100%;\n",
       "  background-color: #14A76C;\n",
       "  color: black;\n",
       "\tpadding: 2px;\n",
       "  padding-left: 5px;\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".l2 {\n",
       "\tfont-style: normal;\n",
       "\tfont-size: 100%;\n",
       "  background-color: #FFE400;\n",
       "  color: black;\n",
       "\tpadding: 2px;\n",
       "  padding-left: 5px;\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".l3 {\n",
       "\tfont-style: normal;\n",
       "\tfont-size: 100%;\n",
       "  background-color: #FF652F;\n",
       "  color: black;\n",
       "\tpadding: 2px;\n",
       "  padding-left: 5px;\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".points {\n",
       "\tfont-style: italic;\n",
       "}\n",
       "\n",
       "ol.lower_roman {\n",
       "    list-style-type: lower-roman;\n",
       "}\n",
       "\n",
       "ol.characters {\n",
       "    list-style-type: lower-alpha;\n",
       "}\n",
       "\n",
       "/* Style einer Code-Cell */\n",
       ".CodeMirror-code {\n",
       "\tbackground-color: #ededed\n",
       "}\n",
       "\n",
       "/* Style eines Kommentars im Code √§ndern. */\n",
       ".cm-s-ipython span.cm-comment {\n",
       "\n",
       "}\n",
       "\n",
       ".cm-s-ipython span.cm-atom {\n",
       "\n",
       "}\n",
       "\n",
       ".cm-s-ipython span.cm-number {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style eines Python-Keywords √§ndern */\n",
       ".cm-s-ipython span.cm-keyword {\n",
       "\tcolor: #B000B0\n",
       "}\n",
       "\n",
       ".cm-s-ipython span.cm-def {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style einer Python-Variable √§ndern */\n",
       ".cm-s-ipython span.cm-variable {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style einer Property √§ndern */\n",
       ".cm-s-ipython span.cm-property {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style eines Python-Operators √§ndern */\n",
       ".cm-s-ipython span.cm-operator {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style eines Python-Strings √§ndern */\n",
       ".cm-s-ipython span.cm-string {\n",
       "\tcolor: brown;\n",
       "}\n",
       "\n",
       "/* Style einer eingebauten Funktion √§ndern (z.B. \"open\") */\n",
       ".cm-s-ipython span.cm-builtin {\n",
       "\n",
       "}\n",
       "\n",
       "/* Hebt hervor, welche Klammern zueinander passen */\n",
       ".cm-s-ipython .CodeMirror-matchingbracket {\n",
       "\n",
       "}\n",
       "\n",
       ".cm-s-ipython span.cm-variable-2 {\n",
       "\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "HTML(\"<style>\" + open(\"style.css\").read() + \"</style>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"headline\">\n",
    "Language Technology / Sprachtechnologie\n",
    "<br><br>\n",
    "Wintersemester 2019/2020\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"description\">\n",
    "    √úbung zum Thema <i id=\"topic\">\"Named Entity / Coreference\"</i>\n",
    "    <br><br>\n",
    "    Deadline Abgabe: <i #id=\"submission\">Thursday, 14.11.2019 (23:55 Uhr)</i>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pr√§senz√ºbung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.probability import ConditionalFreqDist\n",
    "from nltk.corpus import*\n",
    "from nltk.book import*\n",
    "from nltk.chunk import *\n",
    "from nltk.chunk.util import *\n",
    "from nltk.chunk.regexp import *\n",
    "\n",
    "from sklearn import datasets, svm, tree, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd \n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import gazetteers, names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warm Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 4.1:</i> Named entitiy recognition: <br>\n",
    "</div>\n",
    "\n",
    "Which of the following statements are true?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The goal of a named entity recognition (NER) system is to identify all textual mentions of the named entities.\n",
    "2. Named entity recognition is a method to extract person names from text.\n",
    "3. Named entities are language independent.\n",
    "4. In named entitiy recognition we need to be able to identify the beginning and the end of multi-token sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">L√∂sung:</strong>\n",
    "\n",
    "1. True, a named entity recognition (NER) system should identify all textual mentions of the named entities.\n",
    "2. True. PERSON is a valid named entity type, however the NE recognition systems may extract numerous other types as LOCATION or ORGANIZATION.\n",
    "3. False. Although names of persons are usually not translated (besides the alphabet), currencies and dates can be specific to one language. Countries (GPE: geo-political entities) are sometimes translated (e.g. Elfenbeink√ºste - Ivory coast - Cote d'Ivoire) \n",
    "4. True, since named entities may consist of more than one word (e.g. George W. Bush)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a Named Entities Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A type of noun phrase that is of particular interest is a named entity. This might be a person, such as Albert Einstein, or a place, such as Duisburg or a business, such as Irish Pub. <br>\n",
    "In general, this is a hard problem. Words can have multiple uses, and there‚Äôs an unbounded number of possible names. Within a domain, though, we can have better luck. NLTK provides a classifier that has already been trained to recognize named entities, accessed with the function nltk.ne_chunk() <br>\n",
    "The table below states the commonly used types of named entities, as they are provided by nltk:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| NE Type | Examples  |\n",
    "|------|------|\n",
    "|ORGANIZATION|Georgia-Pacific Corp., WHO\n",
    "|PERSON| Eddy Bonte, President Obama\n",
    "|LOCATION|Murray River, Mount Everest\n",
    "|DATE|June, 2008-06-29\n",
    "|TIME|two fifty a m, 1:30 p.m.\n",
    "|MONEY|175 million Canadian Dollars, GBP 10.40\n",
    "|PERCENT|twenty pct, 18.75%\n",
    "|FACILITY|Washington Monument, Stonehenge\n",
    "|GPE (geo-political entities)|South East Asia, Midlothian\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 4.2:</i> <br>\n",
    "</div>\n",
    "\n",
    "Use the sentence below: <br><br>\n",
    "The capital of the United States of America is named after the first US president George Washington."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">4.2.1</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Use word_tokenize to tokenize the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">L√∂sung:</strong>\n",
    "\n",
    "We tokenize the above text using the expression nltk.word_tokenize(sentence). The tokenizer outputs the list of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['The',\n 'capital',\n 'of',\n 'the',\n 'United',\n 'States',\n 'of',\n 'America',\n 'is',\n 'named',\n 'after',\n 'the',\n 'first',\n 'US',\n 'president',\n 'George',\n 'Washington',\n '.']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(\"The capital of the United States of America is named after the first US president George Washington.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">4.2.2</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Use nltk.pos_tag to tag the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">L√∂sung:</strong>\n",
    "\n",
    "We assign part-of-speech tags to the above text using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('capital', 'NN'), ('of', 'IN'), ('the', 'DT'), ('United', 'NNP'), ('States', 'NNPS'), ('of', 'IN'), ('America', 'NNP'), ('is', 'VBZ'), ('named', 'VBN'), ('after', 'IN'), ('the', 'DT'), ('first', 'JJ'), ('US', 'NNP'), ('president', 'NN'), ('George', 'NNP'), ('Washington', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "sentence = nltk.word_tokenize(\"The capital of the United States of America is named after the first US president George Washington.\")\n",
    "sentence = nltk.pos_tag(sentence)\n",
    "print (sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">4.2.3</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Use nltk.ne_chunk to chunk the tagged sentence. Experiment with the argument \"binary\". What is the difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">L√∂sung:</strong>\n",
    "\n",
    "We extract named entities from the above text using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  The/DT\n",
      "  capital/NN\n",
      "  of/IN\n",
      "  the/DT\n",
      "  (GPE United/NNP States/NNPS)\n",
      "  of/IN\n",
      "  (GPE America/NNP)\n",
      "  is/VBZ\n",
      "  named/VBN\n",
      "  after/IN\n",
      "  the/DT\n",
      "  first/JJ\n",
      "  (GPE US/NNP)\n",
      "  president/NN\n",
      "  (PERSON George/NNP Washington/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "tree = nltk.ne_chunk(sentence, binary=False)\n",
    "print (tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that setting the 'binary' parameter to True outputs named entities without types. For example the excerpt \"('America','NNP')\" labels America as a Named Entity. Whereas, the default setting of the 'binary' parameter to False enables the system to output Named Entity types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">4.2.4</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Draw (.draw()) and analyze the resulting tree structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">L√∂sung:</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named '_tkinter'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-22-34ff0bdea0a1>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mtkinter\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mtree\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnltk\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mne_chunk\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msentence\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbinary\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mtree\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdraw\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/tkinter/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0msys\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     35\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 36\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0m_tkinter\u001B[0m \u001B[0;31m# If this fails your Python may not be configured for Tk\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     37\u001B[0m \u001B[0mTclError\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_tkinter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTclError\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtkinter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconstants\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named '_tkinter'"
     ]
    }
   ],
   "source": [
    "import tkinter\n",
    "tree = nltk.ne_chunk(sentence, binary=True)\n",
    "tree.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the named entities are extracted: United States, America, US and George Washington. <br>\n",
    "Also the tree structure is very flat, with the bottom layer of extracted entities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">4.2.5</i> <i class=\"l3\">L3</i> <br>\n",
    "</div>\n",
    "\n",
    "Write a function extract_entity_names(tree), that extracts all identified named entities of the given tree and returns it as a list of words.<br>\n",
    "Since 'tree' is is a nested structure implement this function using a recursion. It is standard to use recursice function to traverse a tree. The listing below defines an algorithm to traverse a tree. You may change it to fit your purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( <bound method Tree.label of Tree('S', [('The', 'DT'), ('capital', 'NN'), ('of', 'IN'), ('the', 'DT'), Tree('GPE', [('United', 'NNP'), ('States', 'NNPS')]), ('of', 'IN'), Tree('GPE', [('America', 'NNP')]), ('is', 'VBZ'), ('named', 'VBN'), ('after', 'IN'), ('the', 'DT'), ('first', 'JJ'), Tree('GPE', [('US', 'NNP')]), ('president', 'NN'), Tree('PERSON', [('George', 'NNP'), ('Washington', 'NNP')]), ('.', '.')])>\n",
      "('The', 'DT')\n",
      "('capital', 'NN')\n",
      "('of', 'IN')\n",
      "('the', 'DT')\n",
      "( <bound method Tree.label of Tree('GPE', [('United', 'NNP'), ('States', 'NNPS')])>\n",
      "('United', 'NNP')\n",
      "('States', 'NNPS')\n",
      ")\n",
      "('of', 'IN')\n",
      "( <bound method Tree.label of Tree('GPE', [('America', 'NNP')])>\n",
      "('America', 'NNP')\n",
      ")\n",
      "('is', 'VBZ')\n",
      "('named', 'VBN')\n",
      "('after', 'IN')\n",
      "('the', 'DT')\n",
      "('first', 'JJ')\n",
      "( <bound method Tree.label of Tree('GPE', [('US', 'NNP')])>\n",
      "('US', 'NNP')\n",
      ")\n",
      "('president', 'NN')\n",
      "( <bound method Tree.label of Tree('PERSON', [('George', 'NNP'), ('Washington', 'NNP')])>\n",
      "('George', 'NNP')\n",
      "('Washington', 'NNP')\n",
      ")\n",
      "('.', '.')\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def traverse(t):\n",
    "    try:\n",
    "        t.label\n",
    "    except AttributeError:\n",
    "        print (t)\n",
    "    else:\n",
    "        #Now we know that t.node is defined\n",
    "        print ('(', t.label),\n",
    "        for child in t:\n",
    "            traverse(child)\n",
    "        print (')'),\n",
    "        \n",
    "traverse(tree)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">L√∂sung:</strong>\n",
    "\n",
    "Refer to the code in the following listing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree: \n",
      " (S\n",
      "  The/DT\n",
      "  capital/NN\n",
      "  of/IN\n",
      "  the/DT\n",
      "  (NE United/NNP States/NNPS)\n",
      "  is/VBZ\n",
      "  named/VBN\n",
      "  after/IN\n",
      "  the/DT\n",
      "  first/JJ\n",
      "  (NE US/NNP)\n",
      "  president/NN\n",
      "  (NE George/NNP Washington/NNP))\n",
      "Named entities:  [['United States'], ['US'], ['George Washington']]\n"
     ]
    }
   ],
   "source": [
    "def extract_entity_names(tree):\n",
    "    '''This function exctracts all named entities from a tree. \n",
    "    If a tree node has the label 'NE' it extracts all values of the leaves and adds it to the set of named entities\n",
    "    This named entity is coverted to a list and returned'''\n",
    "    \n",
    "    entity_names = []\n",
    "    try:\n",
    "        if tree.label() == 'NE':\n",
    "            entity = ' '.join(leaf[0] for leaf in tree.leaves())\n",
    "            entity_names.append(entity)\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    else:\n",
    "        for child in tree:\n",
    "            entity = extract_entity_names(child)\n",
    "            if len(entity)>0:\n",
    "                entity_names.append(entity)\n",
    "    return entity_names\n",
    "    \n",
    "\n",
    "text = \"The capital of the United States is named after the first US president George Washington\"\n",
    "\n",
    "sentence = nltk.word_tokenize(text)\n",
    "sentence = nltk.pos_tag(sentence)\n",
    "tree = nltk.ne_chunk(sentence, binary = True)\n",
    "\n",
    "print (\"Tree: \\n\",tree)\n",
    "print (\"Named entities: \",extract_entity_names(tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision, Recall, F-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 4.3:</i> <br>\n",
    "</div>\n",
    "\n",
    "The following confusion matrix shows the evaluation result of a named entities classifier. The columns contain the gold standard and the rows the system output. The target class is NE.\n",
    "\n",
    "Confusion Matrix |NE | no NE |\n",
    "-|-|-|\n",
    "NE| 50 | 30 |\n",
    "no NE| 20 | 200 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">4.3.1</i> <i class=\"l1\">L1</i> <br>\n",
    "</div>\n",
    "How many true positives, true negatives, false positives and false negatives are there? How do you interpret them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">L√∂sung:</strong>\n",
    "\n",
    "There are 50 true positives (System and Gold say \"NE\"), and 200 true negatives (System and Gold say \"no NE\"): These are the cases where the system made the correct decision.\n",
    "\n",
    "There are 30 false positives (System says \"NE\" but correct would be \"no NE\"), and 20 false negatives (System says \"no NE\" but correct would be \"NE\"): These are the cases where the system made an incorrect decision.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">4.3.2</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "Compute precision, recall and F-score given the confusion matrix above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">L√∂sung:</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = 50/(50+30)\n",
    "recall = 50/(50+20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F-Score: \", 2*precision*recall/(precision+recall) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building your own Named Entities Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 4.4:</i> <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">4.4.1</i> <i class=\"l1\">L1</i> <br>\n",
    "</div>\n",
    "What does the following code do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         WORD     NE\n",
      "0           &  False\n",
      "1          gt  False\n",
      "2           ;  False\n",
      "3           *  False\n",
      "4         The  False\n",
      "5     soldier  False\n",
      "6         was  False\n",
      "7      killed  False\n",
      "8        when  False\n",
      "9     another  False\n",
      "10  avalanche  False\n",
      "11        hit  False\n",
      "12         an  False\n",
      "13       army  False\n",
      "14   barracks  False\n",
      "15         in  False\n",
      "16        the  False\n",
      "17   northern  False\n",
      "18       area  False\n",
      "19         of  False\n",
      "20    Sonmarg   True\n",
      "21          ,  False\n",
      "22       said  False\n",
      "23          a  False\n",
      "24   military  False\n",
      "25  spokesman  False\n",
      "26          .  False\n",
      "27          &  False\n",
      "28         gt  False\n",
      "29          ;  False\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"NER_clean.csv\", delimiter = \"\\t\", encoding=\"utf-8\", names=[\"WORD\", \"NE\"], quoting=3)\n",
    "df[\"WORD\"] = df[\"WORD\"].apply(str)\n",
    "print(df[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">L√∂sung:</strong>\n",
    "\n",
    "A csv file is read in and converted to a data frame with two columns: One contains the word and the other one a binary distinction whether the word is a named entity (\"True\") or not (\"False\"). (quoting = 3 is necessary to also read in quotation marks as regular tokens).\n",
    "The second line of code only makes sure that anything in the first column is treated as a string (even numbers). Finally, the first 30 rows of the data frame are printed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">4.4.2</i> <i class=\"l1\">L1</i> <br>\n",
    "</div>\n",
    "What does the following code do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         WORD     NE  WORDLENGTH\n",
      "0           &  False           1\n",
      "1          gt  False           2\n",
      "2           ;  False           1\n",
      "3           *  False           1\n",
      "4         The  False           3\n",
      "5     soldier  False           7\n",
      "6         was  False           3\n",
      "7      killed  False           6\n",
      "8        when  False           4\n",
      "9     another  False           7\n",
      "10  avalanche  False           9\n",
      "11        hit  False           3\n",
      "12         an  False           2\n",
      "13       army  False           4\n",
      "14   barracks  False           8\n",
      "15         in  False           2\n",
      "16        the  False           3\n",
      "17   northern  False           8\n",
      "18       area  False           4\n",
      "19         of  False           2\n",
      "20    Sonmarg   True           7\n",
      "21          ,  False           1\n",
      "22       said  False           4\n",
      "23          a  False           1\n",
      "24   military  False           8\n",
      "25  spokesman  False           9\n",
      "26          .  False           1\n",
      "27          &  False           1\n",
      "28         gt  False           2\n",
      "29          ;  False           1\n"
     ]
    }
   ],
   "source": [
    "words =list(df.loc[:, \"WORD\"])\n",
    "df[\"WORDLENGTH\"] = [len(word) for word in words]\n",
    "print(df[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">L√∂sung:</strong>\n",
    "    \n",
    "A third column is added which contains the length the token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">4.4.3</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Add 4 columns to the data frame which contain\n",
    "\n",
    "- whether a word is capitalized (True/False)\n",
    "- whether a word is fully written in uppercase (True/False)\n",
    "- whether the word is a noun (True/False)\n",
    "- whether the word appears in the corpus \"names\" or \"gazetteers\" from NLTK (True/False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">L√∂sung:</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"IS_CAPITALIZED\"] = [word.istitle() for word in words]\n",
    "df[\"IS_UPPER\"] = [word.isupper() for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         WORD     NE  WORDLENGTH  IS_CAPITALIZED  IS_UPPER  IN_LIST   NOUN\n",
      "0           &  False           1           False     False    False  False\n",
      "1          gt  False           2           False     False    False   True\n",
      "2           ;  False           1           False     False    False  False\n",
      "3           *  False           1           False     False    False  False\n",
      "4         The  False           3            True     False    False  False\n",
      "5     soldier  False           7           False     False    False   True\n",
      "6         was  False           3           False     False    False  False\n",
      "7      killed  False           6           False     False    False  False\n",
      "8        when  False           4           False     False    False  False\n",
      "9     another  False           7           False     False    False  False\n",
      "10  avalanche  False           9           False     False    False   True\n",
      "11        hit  False           3           False     False    False  False\n",
      "12         an  False           2           False     False    False  False\n",
      "13       army  False           4           False     False    False   True\n",
      "14   barracks  False           8           False     False    False   True\n",
      "15         in  False           2           False     False    False  False\n",
      "16        the  False           3           False     False    False  False\n",
      "17   northern  False           8           False     False    False  False\n",
      "18       area  False           4           False     False    False   True\n",
      "19         of  False           2           False     False    False  False\n",
      "20    Sonmarg   True           7            True     False    False   True\n",
      "21          ,  False           1           False     False    False  False\n",
      "22       said  False           4           False     False    False  False\n",
      "23          a  False           1           False     False    False  False\n",
      "24   military  False           8           False     False    False  False\n",
      "25  spokesman  False           9           False     False    False   True\n",
      "26          .  False           1           False     False    False  False\n",
      "27          &  False           1           False     False    False  False\n",
      "28         gt  False           2           False     False    False   True\n",
      "29          ;  False           1           False     False    False  False\n"
     ]
    }
   ],
   "source": [
    "print(df[:30])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_gaz = set(gazetteers.words())\n",
    "set_names = set(names.words())\n",
    "df[\"IN_LIST\"] = [word in set_gaz or word in set_names for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = pos_tag(words, tagset=\"universal\")\n",
    "df[\"NOUN\"] = [tag == \"NOUN\" for (word, tag) in pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">4.4.4</i> <i class=\"l3\">L3</i> <br>\n",
    "</div>\n",
    "\n",
    "The following code creates a Decision Tree Classifier which classifies whether a token is a named entity or not based on the features you provided above. The data are split in a training and a test set and the variable \"predicted\" contains the predicted labels (NE = \"True\", no NE =\"False\") while \"gold\" contains the corresponding gold labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:, 2:len(df.columns)]\n",
    "y = df.iloc[:, [1]]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "import sklearn\n",
    "\n",
    "c_tree = sklearn.tree.DecisionTreeClassifier(max_depth=4)\n",
    "c_tree.fit(x_train, y_train)\n",
    "\n",
    "predicted = list(c_tree.predict(x_test))\n",
    "gold = list(y_test.loc[:, \"NE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        WORD     NE  WORDLENGTH  IS_CAPITALIZED  IS_UPPER  IN_LIST   NOUN\n",
      "0          &  False           1           False     False    False  False\n",
      "1         gt  False           2           False     False    False   True\n",
      "2          ;  False           1           False     False    False  False\n",
      "3          *  False           1           False     False    False  False\n",
      "4        The  False           3            True     False    False  False\n",
      "...      ...    ...         ...             ...       ...      ...    ...\n",
      "23389   with  False           4           False     False    False  False\n",
      "23390   this  False           4           False     False    False  False\n",
      "23391  dress  False           5           False     False    False   True\n",
      "23392   code  False           4           False     False    False   True\n",
      "23393      üòÇ  False           1           False     False    False   True\n",
      "\n",
      "[23394 rows x 7 columns]\n",
      "       WORDLENGTH  IS_CAPITALIZED  IS_UPPER  IN_LIST   NOUN\n",
      "0               1           False     False    False  False\n",
      "1               2           False     False    False   True\n",
      "2               1           False     False    False  False\n",
      "3               1           False     False    False  False\n",
      "4               3            True     False    False  False\n",
      "...           ...             ...       ...      ...    ...\n",
      "23389           4           False     False    False  False\n",
      "23390           4           False     False    False  False\n",
      "23391           5           False     False    False   True\n",
      "23392           4           False     False    False   True\n",
      "23393           1           False     False    False   True\n",
      "\n",
      "[23394 rows x 5 columns]\n",
      "          NE\n",
      "0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "...      ...\n",
      "23389  False\n",
      "23390  False\n",
      "23391  False\n",
      "23392  False\n",
      "23393  False\n",
      "\n",
      "[23394 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)\n",
    "print(x)\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the predicted and the gold labels, compute precision, recall and F-score for the classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">L√∂sung:</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.7884615384615384\n",
      "recall: 0.10875331564986737\n",
      "f-score: 0.19114219114219116\n"
     ]
    }
   ],
   "source": [
    "tp = sum(pair == (True, True) for pair in zip(predicted, gold))\n",
    "fp = sum(pair == (True, False) for pair in zip(predicted, gold))\n",
    "fn = sum(pair == (False, True) for pair in zip(predicted, gold))\n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "fscore = 2*precision*recall/(precision+recall)\n",
    "\n",
    "print(\"precision:\", precision)\n",
    "print(\"recall:\", recall)\n",
    "print(\"f-score:\", fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compare your results to the built-in classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.93      1.00      0.96      4302\n",
      "        True       0.79      0.11      0.19       377\n",
      "\n",
      "    accuracy                           0.93      4679\n",
      "   macro avg       0.86      0.55      0.58      4679\n",
      "weighted avg       0.92      0.93      0.90      4679\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(gold,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 4.1:</i> \n",
    "</div>\n",
    "\n",
    "<i class=\"subtask\">4.1.1</i> \n",
    "Annotate all named entities in the file \"Langtech_NER.txt\"\n",
    "\n",
    "* The file contains 100 German sentences (note that the sentences do not form a coherent text) and each sentence may contain one or more named entities but it is also possible that there is no named entity in a sentence\n",
    "<br><br>\n",
    "* The 4 named entity types to annotate are PERSON (PER), ORGANIZATION (ORG), LOCATION (LOC), OTHER (OTH). For further information about which named entity belongs to which type, please refer to the \"NoSta-D-TagSet\" on page 6 in the file \"Clarin_NoSta-D_NER-AnnotationGuidelines.pdf\" that you can download from Moodle. Important: you are not asked to follow these annotation guidelines completely. Especially, note the followning:\n",
    "     * Anything that is tagged with \"deriv\" or \"part\" tags according to these guidelines is ignored (e.g. LOCderiv, ORGpart)\n",
    "     * In our annotation, there are no nested named entities. For example \"Bayern M√ºnchen\" is labeled as ORG and the individual parts \"Bayern\" and \"M√ºnchen\" are not labeled as LOC. As a general rule, the longest possible span gets the label.\n",
    " <br>\t\n",
    "<br>\n",
    "* Upload the annotated file (ending with \".ann\", see below), to Moodle. Make sure that the filename contains your name!\n",
    "\n",
    "<i class=\"subtask\">4.1.2</i> \n",
    "\n",
    "Write down at least 5 different cases that you found difficult to annotate. For each, write down 1-2 sentences explaining why it was difficult (e.g. by saying which other label could have applied and why or why you were unsure whether something is a named entity or not). Upload your descriptions to Moodle as a PDF file.\n",
    "\n",
    "\n",
    "\n",
    "### Technical instructions\n",
    "\n",
    "\n",
    "- Download the annotation tool YEDDA from https://github.com/jiesutd/YEDDA\n",
    "\n",
    "- Attention: YEDDA requires Python 2.7, so make sure you have this version installed!\n",
    "\n",
    "- To start the annotation, open a console (in the YEDDA-master folder) and type python YEDDA.py (make sure you start it with Python 2 not Python 3, so maybe you have to type something like /path/to/python2 YEDDA.py !)\n",
    "\n",
    "- Download the file \"Langtech_NER.config\" from Moodle and place it in the folder \"YEDDA-master/configs/\".\n",
    "\n",
    "- To open the sentences to annotate, click on \"open\" and select the file \"Langtech_NER.txt\" (or \"Langtech_NER.ann\" if you have already saved an annotated version and want to continue)\n",
    "\n",
    "- Select the correct set of labels: In the drop down menu under \"Map Templates\" on the right hand side, select the file \"Langtech_NER.config\"\n",
    "\n",
    "- To annotate a named entity, mark the whole Named Entity and press the key on the keyboard that is associated with the right label (A: PERSON, B: ORGANISATION, C:LOCATION, D:OTHER)\n",
    "\n",
    "- To change a label, click within the entity span and press the key for the new label\n",
    "\n",
    "- To remove a label, click within the entity span and press 'q' . Important: In order to remove the label, do not mark the whole entity. If you then press 'q' this will remove the whole entity, not just the label!\n",
    "\n",
    "- Clicking on \"Export\" will save the annotated text. Note: two files will be saved, one ending with *.ann and one with *.anns. Upload the one ending with *.ann to Moodle (change the filename so that it contains your name!)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}