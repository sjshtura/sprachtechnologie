{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>/* Style des gesamten Dokuments */\n",
       "#notebook-container {\n",
       "\tfont-family: \"NimbusMonL-ReguObli\";\n",
       "\tfont-size: 120%\n",
       "}\n",
       "\n",
       "/* Style für die Überschrift: Zentriert diese und stellt sie fett dar. */\n",
       ".headline {\n",
       "\ttext-align: center;\n",
       "\tfont-weight: bold;\n",
       "\tfont-size: 185.7%\n",
       "}\n",
       "\n",
       "/* Style für die Aufgabenbeschreibung. Z.B.: \"Übung zum Thema...\" */\n",
       ".description {\n",
       "\ttext-align: center;\n",
       "\tfont-size: 145.7%\n",
       "}\n",
       "\n",
       "/* Hebt das Abgabedatum fett und kursiv hervor */\n",
       "#submission {\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "\n",
       "/* Style für das eigentliche Thema. Z.B.: \"Intelligenz\" */\n",
       "#topic {\n",
       "\tfont-style: italic;\n",
       "}\n",
       "\n",
       ".task_description {\n",
       "\tmargin-bottom: 20px;\n",
       "}\n",
       "\n",
       "/* Hebt die Aufgabennummerierung fett hervor. */\n",
       ".task {\n",
       "\tfont-style: normal;\n",
       "\tfont-weight: bold;\n",
       "\tfont-size: 120%;\n",
       "\tborder-bottom: 2px solid black;\n",
       "  background-color: #97CAEF;\n",
       "  color: black;\n",
       "\tpadding: 2px;\n",
       "  padding-left: 50px;\n",
       "  padding-right: 50px;\n",
       "}\n",
       "\n",
       ".subtask {\n",
       "\tfont-style: normal;\n",
       "\tfont-size: 100%;\n",
       "  background-color: #CAFAFE;\n",
       "  color: black;\n",
       "\tpadding: 2px;\n",
       "  padding-left: 25px;\n",
       "  padding-right: 25px;\n",
       "}\n",
       "\n",
       ".l1 {\n",
       "\tfont-style: normal;\n",
       "\tfont-size: 100%;\n",
       "  background-color: #14A76C;\n",
       "  color: black;\n",
       "\tpadding: 2px;\n",
       "  padding-left: 5px;\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".l2 {\n",
       "\tfont-style: normal;\n",
       "\tfont-size: 100%;\n",
       "  background-color: #FFE400;\n",
       "  color: black;\n",
       "\tpadding: 2px;\n",
       "  padding-left: 5px;\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".l3 {\n",
       "\tfont-style: normal;\n",
       "\tfont-size: 100%;\n",
       "  background-color: #FF652F;\n",
       "  color: black;\n",
       "\tpadding: 2px;\n",
       "  padding-left: 5px;\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".points {\n",
       "\tfont-style: italic;\n",
       "}\n",
       "\n",
       "ol.lower_roman {\n",
       "    list-style-type: lower-roman;\n",
       "}\n",
       "\n",
       "ol.characters {\n",
       "    list-style-type: lower-alpha;\n",
       "}\n",
       "\n",
       "/* Style einer Code-Cell */\n",
       ".CodeMirror-code {\n",
       "\tbackground-color: #ededed\n",
       "}\n",
       "\n",
       "/* Style eines Kommentars im Code ändern. */\n",
       ".cm-s-ipython span.cm-comment {\n",
       "\n",
       "}\n",
       "\n",
       ".cm-s-ipython span.cm-atom {\n",
       "\n",
       "}\n",
       "\n",
       ".cm-s-ipython span.cm-number {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style eines Python-Keywords ändern */\n",
       ".cm-s-ipython span.cm-keyword {\n",
       "\tcolor: #B000B0\n",
       "}\n",
       "\n",
       ".cm-s-ipython span.cm-def {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style einer Python-Variable ändern */\n",
       ".cm-s-ipython span.cm-variable {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style einer Property ändern */\n",
       ".cm-s-ipython span.cm-property {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style eines Python-Operators ändern */\n",
       ".cm-s-ipython span.cm-operator {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style eines Python-Strings ändern */\n",
       ".cm-s-ipython span.cm-string {\n",
       "\tcolor: brown;\n",
       "}\n",
       "\n",
       "/* Style einer eingebauten Funktion ändern (z.B. \"open\") */\n",
       ".cm-s-ipython span.cm-builtin {\n",
       "\n",
       "}\n",
       "\n",
       "/* Hebt hervor, welche Klammern zueinander passen */\n",
       ".cm-s-ipython .CodeMirror-matchingbracket {\n",
       "\n",
       "}\n",
       "\n",
       ".cm-s-ipython span.cm-variable-2 {\n",
       "\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>\" + open(\"style.css\").read() + \"</style>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"headline\">\n",
    "Language Technology / Sprachtechnologie\n",
    "<br><br>\n",
    "Wintersemester 2019/2020\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"description\">\n",
    "    Übung zum Thema <i id=\"topic\">\"Plagiarism / Authorship\"</i>\n",
    "    <br><br>\n",
    "    Deadline Abgabe: <i #id=\"submission\">Thursday, 28.11.2019 (23:55 Uhr)</i>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Präsenzübung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import inaugural, brown, shakespeare, genesis, gutenberg\n",
    "from nltk.book import*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 6.1:</i> <br>\n",
    "</div>\n",
    "\n",
    "When we want to analyse the typical fingerprint of writers, we are often interested in features that are independent from a specific genre or topic.\n",
    " \n",
    "Which of the following features do you think are most topic-dependent and why?\n",
    "* Most frequent verbs\n",
    "* Most frequent prepositions\n",
    "* Most frequent named entities\n",
    "* Most frequent pronouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type-Token Ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 6.2:</i> <i class=\"l3\">L3</i><br>\n",
    "</div>\n",
    "Type-Token-Ratio is a measure of lexical diversity and computed by dividing the number of different types by the overall number of tokens in a text. <br> Implement a method that computes the type-token-ratio for an input text.\n",
    "What happens if you apply this method to the first 100, 500, 1000, 2000, 10000 and 20000 word in Romeo and Julia (Shakespeare corpus)? <br> Can you explain your observation?\n",
    "Discuss what you could do about it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 6.3:</i> <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">6.3.1</i> <i class=\"l1\">L1</i> <br>\n",
    "</div>\n",
    "\n",
    "Take a look at the function below. If executed, what will be the output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [w for w in brown.words() if w.startswith('en')]\n",
    "print(FreqDist(words).most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">6.3.2</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Change the function above to that it gets the ten most frequent words from the corpus that start with the prefix ”en”, end with the suffix ”ed” and are at least five characters long. Moreover, it should not matter if the word is written in upper or lower case (”Ended” and ”ended” should be regarded as the same word)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">6.3.3</i> <i class=\"l3\">L3</i> <br>\n",
    "</div>\n",
    "\n",
    "Using the Brown corpus, find all words that consist of two other words that are at least 5 characters long, e.g.”storehouse”, but not “infrequent” (in + frequent), as “in” is only 2 characters long. Can you think of an improvement that finds surprising ones like “horizontally” (horizon + tally) instead of normal compositions like “storehouse” (store + house)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morphological Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 6.4:</i> <br>\n",
    "</div>\n",
    "\n",
    "\n",
    "An important problem in computational linguistics is morphological analysis.<br> This consists of breaking down a word into its component pieces, for example losses might be broken down as loss + es. In English, morphology is relatively simple and is mostly comprised of prefixes and suffixes. To get an idea of what suffixes are common in English (and thus could be morphemes), we can look at the frequencies of the last two characters of sufficiently long words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">6.4.1</i> <i class=\"l1\">L1</i> <br>\n",
    "</div>\n",
    "\n",
    "Take a look at the function below. Why is it not suitable for finding the most frequent two-character suffixes in a corpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffixes = [w.lower() for w in brown.words() if w.lower().endswith('en') or w.lower().endswith('ly')]\n",
    "print(FreqDist(suffixes).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">6.4.2</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Improve the function above so that only token with a length of at least five characters are taken into consideration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">6.4.3</i> <i class=\"l3\">L3</i> <br>\n",
    "</div>\n",
    "\n",
    "Improve the function further so that it returns the 20 most frequent two-character suffixes from words with at least five characters from a corpus. <br>\n",
    "As a sanity test, you may want test your function on the words in Sense and Sensibility. If you pass the words of a novel (or any sufficiently large English document) as the argument to your function, you should see some common English suffixes in the output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readability Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 6.5:</i> <br>\n",
    "</div>\n",
    "\n",
    "Readability measures are used to score the reading difficulty of a text, for the purposes of selecting texts of\n",
    "appropriate difficulty for language learners. <br>\n",
    "The Automated Readability Index (ARI) of a text is defined to be:<br>\n",
    "``ARI = 4.71μw + 0.5μs − 21.43``\n",
    "Where ``μw`` is the average number of letters per word, and ``μs`` is the average number of words per sentence, in a given text. <br>\n",
    "As a rough guide, a score of 1 corresponds to the reading level at an age of 6 to 8, a score of 8 corresponds to the typical reading level of a 14 year-old US child. A score of 12 corresponds to the reading level of a 17 year-old."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">6.5.1</i> <i class=\"l1\">L1</i> <br>\n",
    "</div>\n",
    "\n",
    "What does the function below compute?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_readability(sentences):\n",
    "    sentCount = len(sentences)\n",
    "    wordCount = 0\n",
    "    charCount = 0\n",
    "    \n",
    "    print(sentCount)\n",
    "\n",
    "calculate_readability(brown.sents())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">6.5.2</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Enhance the function above so that the number of words is added up in the variable wordCount (if you got two sentences, one with 5 words, one with 8, wordCount should be 13)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">6.5.3</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Enhance the function again, so that in charCount the number of characters from each word is added up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">6.5.4</i> <i class=\"l3\">L3</i> <br>\n",
    "</div>\n",
    "\n",
    "Now change your function, so that it returns a double with the value of the ARI score of the corpus (Hint: print is not a return statement). Then compute the ARI score of the Brown corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">6.5.5</i> <i class=\"l3\">L3</i> <br>\n",
    "</div>\n",
    "\n",
    "Use the inaugural corpus and compare it to the Brown corpus to prove the hypothesis: “Speeches are easier to understand than news.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">6.5.6</i> <i class=\"l3\">L3</i> <br>\n",
    "</div>\n",
    "\n",
    "Compute the readability score of all inaugural speeches. Plot it. Discuss the changes over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 6.6.:</i> <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">6.6.1.</i> <i class=\"l1\">L1</i> <br>\n",
    "</div>\n",
    "\n",
    "Look at the code below. Describe what the function does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostCommon(n):\n",
    "    mc = FreqDist(text1)\n",
    "    words = []\n",
    "    for m in mc.most_common(n):\n",
    "        if len(m[0]) ==3:\n",
    "            words.append(m)\n",
    "    return words\n",
    "\n",
    "mostCommon(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">6.6.2</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Take a look at the code below. Enhance the function shorten (c,n,part) to process a text, omitting the n most frequently occurring words of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moby = text1\n",
    "sense = text2\n",
    "chat = text5\n",
    "def shorten(c,n,part):#(corpus, number, test on)\n",
    "    #todo\n",
    "    \n",
    "print(shorten(moby, 100))\n",
    "print(shorten(sense, 100))\n",
    "print(shorten(sense, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">6.6.3.</i> <i class=\"l3\">L3</i> <br>\n",
    "</div>\n",
    "\n",
    "Enhance your code so that results not only for one but for various values of n (e.g. 10, 100, 500) are shown. Experiment with the values of n to find a useful limit for shortening a text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import shakespeare\n",
    "from nltk.corpus import genesis\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.corpus import brown\n",
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "from sklearn import datasets, svm, tree, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">6.1.</i> :::10 Homework points:::\n",
    "</div>\n",
    "In the following, you will try out existing features for authorship attribution and implement additional ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">6.1.1</i> \n",
    "</div>\n",
    "\n",
    "Consider the following code, it computes 3 different features. \n",
    "Can you tell what each feature computes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeFeature1(text):\n",
    "    sum = 0;\n",
    "    for word in text:\n",
    "        sum+= len(word)\n",
    "    return sum/len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRelevantCategories(text, num):\n",
    "    taggedWordList = pos_tag(text)\n",
    "    fd = nltk.FreqDist((t1, t2) for ((w1, t1), (w2, t2)) in nltk.bigrams(taggedWordList))\n",
    "    res = []\n",
    "    for (tag, freq) in fd.most_common(num):\n",
    "        res.append(tag)\n",
    "    return res\n",
    "\n",
    "def computeFeature2(text, cats):\n",
    "    taggedWordList = pos_tag(text)\n",
    "    fd = nltk.FreqDist((t1, t2) for ((w1, t1), (w2, t2)) in nltk.bigrams(taggedWordList))\n",
    "    res = []\n",
    "    for cat in cats:\n",
    "        res.append(fd.freq(cat))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeFeature3(text):\n",
    "    taggedWordList = pos_tag(text, tagset='universal')\n",
    "    fd_tags = nltk.FreqDist(tag for (word, tag) in taggedWordList)\n",
    "    fd_words = nltk.FreqDist(word for (word, tag) in taggedWordList)\n",
    "    return fd_words.freq(';')/fd_tags.freq('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">6.1.2</i> \n",
    "</div>\n",
    "\n",
    "The following code can be used to try the features on an actual classification task.<br>\n",
    "We extract features from either Shakespeare's Hamlet or Melville's Moby Dick and use them to train a classifer for distinguishing between the two authors. <br>\n",
    "We create a new dataframe. <br>\n",
    "We split each book into 300 segments with 100 tokens each. The author is the goldstandard label we want to predict.<br>\n",
    "Note that for the second feature, we first need to determine which are the most frequent categories (of what we cannot tell you, because this is what you are supposed to figure that out :) ) in the data in general to be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "num = 300\n",
    "numTokens = 100\n",
    "numCategoriesToConsider = 5\n",
    "df['GOLD'] = [\"melville\" for i in range(0,num)]+[\"shakespeare\" for i in range(0,num)]\n",
    "df['FEATURE1'] = [computeFeature1(gutenberg.words('melville-moby_dick.txt')[i*numTokens:(i+1)*numTokens]) for i in range(0,num)]+[computeFeature1(gutenberg.words('shakespeare-hamlet.txt')[i*numTokens:(i+1)*numTokens]) for i in range(0,num)]\n",
    "allTexts = gutenberg.words('melville-moby_dick.txt')[:num*numTokens]+gutenberg.words('shakespeare-hamlet.txt')[num*numTokens]\n",
    "tags = getRelevantCategories(allTexts, numCategoriesToConsider)\n",
    "for f in range(0,numCategoriesToConsider):\n",
    "    df['FEATURE2_'+str(f)] = [computeFeature2(gutenberg.words('melville-moby_dick.txt')[i*numTokens:(i+1)*numTokens], tags)[f] for i in range(0,num)]+[computeFeature2(gutenberg.words('shakespeare-hamlet.txt')[i*numTokens:(i+1)*numTokens], tags)[f] for i in range(0,num)]\n",
    "df['FEATURE3'] = [computeFeature3(gutenberg.words('melville-moby_dick.txt')[i*numTokens:(i+1)*numTokens]) for i in range(0,num)]+[computeFeature3(gutenberg.words('shakespeare-hamlet.txt')[i*numTokens:(i+1)*numTokens]) for i in range(0,num)]\n",
    "\n",
    "# We can inspect what the features look like\n",
    "print(df[290:310])\n",
    "\n",
    "\n",
    "# Now we train a classifier similar to what we did for Named Entity classifcation\n",
    "x = df.iloc[:, 1:len(df.columns)]\n",
    "y = df.iloc[:, [0]]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "c_tree = DecisionTreeClassifier(max_depth=4)\n",
    "c_tree.fit(x_train, y_train)\n",
    "\n",
    "# ... and evaluate it\n",
    "predicted = list(c_tree.predict(x_test))\n",
    "gold = list(y_test.loc[:, \"GOLD\"])\n",
    "print(classification_report(gold,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you extend the classifier with new features. Implement a method computeFeature4 that also takes a list of words as input and returns the average sentence length in tokens as features. <br> Integrate it into the classifier with the following code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SENTENCELENGTH'] = [computeFeature4(gutenberg.words('melville-moby_dick.txt')[i*numTokens:(i+1)*numTokens]) for i in range(0,num)]+[computeFeature4(gutenberg.words('shakespeare-hamlet.txt')[i*numTokens:(i+1)*numTokens]) for i in range(0,num)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a next feature please extract the frequency of the five most frequent prepositions. First determine which are the most frequent prepositions in the dataset similar to what we saw for feature 2. The code to integrate this feature would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = getMostFrequentPreps(allTexts, 5)\n",
    "print(tags)\n",
    "for f in range(0,5):\n",
    "    df['PREP_'+str(f)] = [computeFeature5(gutenberg.words('melville-moby_dick.txt')[i*numTokens:(i+1)*numTokens], tags)[f] for i in range(0,num)]+[computeFeature5(gutenberg.words('shakespeare-hamlet.txt')[i*numTokens:(i+1)*numTokens], tags)[f] for i in range(0,num)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the same for the most frequent content words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = getMostFrequentContentWords(allTexts, 5)\n",
    "print(tags)\n",
    "for f in range(0,5):\n",
    "    df['FUNCTIONWORD_'+str(f)] = [computeFeature6(gutenberg.words('melville-moby_dick.txt')[i*numTokens:(i+1)*numTokens], tags)[f] for i in range(0,num)]+[computeFeature6(gutenberg.words('shakespeare-hamlet.txt')[i*numTokens:(i+1)*numTokens], tags)[f] for i in range(0,num)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the classifier again with all of the features and compare it to the original performance with the three given features only."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
